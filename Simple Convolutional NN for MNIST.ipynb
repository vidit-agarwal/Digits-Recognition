{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import library\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as k\n",
    "k.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fix random seed for reproductibility\n",
    "seed= 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train , Y_train) , (x_test , y_test)= mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reshape to be sample[samples][pixels][width][height]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0] , 1,28,28).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = x_test.reshape(x_test.shape[0],1,28,28).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# normalize the pixel values to the range 0 and 1 and one hot encode the output variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##normalise the inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "x_test = x_test / 255\n",
    "# one hot encode outputs\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model is trained using logarithmic loss and the ADAM gradient descent algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model() :\n",
    "    #create model\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0,2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128 , activation='relu'))\n",
    "    model.add(Dense(num_classes , activation='softmax'))\n",
    "    ##compile model\n",
    "    model.compile(loss='categorical_crossentropy' , optimizer='adam' , metrics=['accuracy'])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We evaluate the model the same way as before with the multi-layer perceptron. The CNN is fit over 10 epochs with a batch size of 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "175s - loss: 2.3017 - acc: 0.1104 - val_loss: 2.3005 - val_acc: 0.1135\n",
      "Epoch 2/10\n",
      "194s - loss: 2.3014 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 3/10\n",
      "182s - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 4/10\n",
      "188s - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 5/10\n",
      "187s - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3011 - val_acc: 0.1135\n",
      "Epoch 6/10\n",
      "184s - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 7/10\n",
      "182s - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 8/10\n",
      "183s - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 9/10\n",
      "278s - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 10/10\n",
      "369s - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3009 - val_acc: 0.1135\n",
      "Baseline Error: 11.35%\n"
     ]
    }
   ],
   "source": [
    "#build the model\n",
    "model=baseline_model()\n",
    "#fit thr model\n",
    "model.fit(X_train , Y_train , validation_data=(x_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "\n",
    "## final evolution of the model\n",
    "scores = model.evaluate(x_test , y_test , verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
